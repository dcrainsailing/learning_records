# Node2Vec

## Node2Vec简介

### 图嵌入

把节点编码（嵌入）成一个低维，稠密（元素都不为0），连续（元素都是实数）的向量。向量包含原来节点的信息，特别是语义信息。

应用在节点分类、连接预测、图分类、异常检测、聚类等机器学习擅长的场景，前提是向量质量足够好。

在有限D维度内，向量要充分表达节点在图中的信息，特别是语义信息、结构信息、关联信息、社群信息、邻域信息。

图嵌入分类：

节点、边、子图、全图

图嵌入方法：

基于手工构造特征、基于矩阵分解、基于随机游走、基于图神经网络

### DeepWalk

把Word2Vec（Skip-Gram）用在了图里。随机游走序列当作句子，节点当作单词来训练节点的嵌入。

优点：

通过完全随机游走序列编码每个节点的社群、邻域信息。

缺点：

仅能表达相邻节点的社群相似信息，无法表达离得很远但很相似（在节点结构、角色、功能上的相似性）

### Node2Vec

通过有偏随机游走，解决DeepWalk的缺点。

​	$ \alpha = \frac{1}{p}$时，返回上一个节点t（与节点t距离为0）

​	$ \alpha = 1$时，徘徊（与节点t距离为1）

​	$ \alpha = \frac{1}{q}$时，远行（与节点t距离为2）

当$ p $很小时，属于广度优先搜索（BFS），反映微观的邻域，捕捉节点功能角色（structural equivalence）（中枢、桥接、边缘）

当$ q $很小时，属于深度优先搜索（DFS），反映宏观的邻域，捕捉同质社群（homophily）（社交网络）

Node2Vec里是二阶随机游走（二阶马尔科夫），下一个节点取决于当前节点和上一个节点

#### 步骤

1. 生成随机游走采样策略
2. 每个节点生成$r$个随机游走序列
   1. 当前节点根据采样策略$(p,q)$找到下一个节点
3. 通过Skip-Gram训练得到节点嵌入表示

### 总结

- 解决图嵌入问题，将图中的每个节点映射为一个向量（嵌入）
- 向量（嵌入）包含了节点的语义信息（相邻社群和功能角色）
- 语义相似的节点，向量（嵌入）的距离也近
- 向量（嵌入）用于后续的分类、聚类、Link Prediction、推荐等任务
- 在DeepWalk完全随机游走的基础上，Node2Vec增加参数p和q，实现有偏随机游走。不同的p、q组合，对应了不同的探索范围和节点语义
- DFS深度优先探索，相邻的节点，向量（嵌入）距离相近
- BFS广度优先探索，相同功能角色的节点，向量（嵌入）距离相近
- DeepWalk是Node2Vec在$p=1$，$q=1$的特例

### 讨论

* 通过调节$p$、$q$值，实现有偏随机游走，探索节点社群、功能等不同属性
* 首次把节点分类用于Link Prediction
* 可解释性、可拓展性好，性能卓越
* 需要大量随机游走序列训练。
* 距离较远的两个节点无法直接相互影响。看不到全图信息。
* 无监督，仅编码图的连接信息，没有利用节点的属性特征。
* 没有真正用到神经网络和深度学习。

## Node2Vec论文精读

### 摘要

对于网络中的节点和边的预测任务，首先需要做特征工程把它们变成向量。

表示学习（例如DeepWalk）已经有了些非常好的尝试，但表示能力还不够高。无法反映节点更丰富的特征和更多样性的连接属性。

Node2Vec通过把节点映射成连续、低维、稠密的向量，输入图，使用极大似然估计实现向量的训练，输出向量。

Node2Vec定义了非常灵活的有偏随机游走范式，可以灵活探索网络的不同多样化的属性，特征。

### 介绍

节点和边、图的数据挖掘，很多任务都是对节点和边来做预测，可以抽象为节点分类任务和连接预测任务。

任何监督学习的机器学习问题都需要内含丰富语义，有分类区分性，并且相互独立的特征。

对于网络和图，需要把节点Embedding变成一个向量，向量也应该具有丰富的语义信息来反映节点的特征。

1. 通过专家知识，人工构造特征。
2. 通过有监督的机器学习，针对特定任务（目标函数）优化
3. 无监督，构造通用特征（与下游任务无关）

4. 现在的技术，对于无监督学习是不满足的。所以提出了基于矩阵分解的图嵌入。
   1. 无法扩展到更大的图，求特征值会变得很麻烦。
5. 基于随机游走的图嵌入。
   1. Word2Vec，用SGD去优化图嵌入表，用Skip-Gram范式（中心节点预测周围节点）去训练图向量。
   2. 只能采样邻域信息，没有全图信息。

真实的网络是社群同质属性（homophily）和（structural equivalence）两种特质的混合，所以在图嵌入时，算法设计应该足够灵活，兼顾这两种特质：同一社群里的节点，应该编码为相近的Embedding；同一种功能角色的节点，也应该编码为相近的Embedding。

Node2Vec，半监督自监督的学习来进行节点嵌入：

* 优化一个自定义的目标函数，使用SGD，用到Word2Vec的Skip-Gram。

* 直观来讲，就是使用极大似然估计，通过中间节点预测周围节点，使得事件发生的概率最大化。

* 采样的随机游走序列使用二阶有偏随机游走去采样。
  * 一阶随机游走（一阶马尔科夫性），下一节点仅与当前节点有关：DeepWalk，PageRank
  * 二阶随机游走（二阶马尔科夫性），下一节点不仅与当前节点有关，还与上一节点有关。

Node2Vec关键贡献

* 设计了灵活的采样策略，通过有偏随机游走，既可以提取homophily，又可以提取structural equivalence。
* 可以通过调节参数来灵活控制，并且调$p$、$q$有直观的几何解释。最优的$p$、$q$可通过调参得到。
* 不管对节点可以做嵌入，也可以对连接做嵌入。通过二元操作把任意两个节点的embedding组合在一起，作为连接的embedding，去做link prediction。

相关工作

- 传统方法的缺点：基于手工设计特征的图嵌入，但是该方式非常笨拙，不通用；
- 通过机器学习的表示学习，自动获得每个节点的嵌入特征；
  - 基于矩阵分解的图嵌入，例如Laplacian矩阵、PCA方法。
    - 涉及特征值计算很难，并且也不通用。
  - 基于随机游走的图嵌入
    - 套用Word2用中间词预测周围词的方法（Skip-Gram）：
    - DeepWalk和LINE缺少采样策略。
    - Node2Vec通过调参改变搜索空间。
  - 基于监督学习的图嵌入：用节点的标签进行图嵌入，直接优化下游任务的损失函数，使图嵌入适应下游的分类任务。
    - 但很多节点分类场景，标签非常稀疏；用标签训练出的图嵌入，只能用来解决和标签相关的图嵌入。

